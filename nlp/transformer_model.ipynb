{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Genre Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "from collections import Counter\n",
    "import time\n",
    "import json \n",
    "\n",
    "from mxl_tokenizer import MusicXML_to_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MusicXMLDataset(Dataset):\n",
    "    def __init__(self, json_path, vocab=None, max_len=512):\n",
    "        # Load the preprocessed entries from the JSON file.\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            self.entries = json.load(f)\n",
    "        \n",
    "        # Optionally filter entries (e.g., only those from a specific directory)\n",
    "        self.entries = [entry for entry in self.entries if \"/mxl/0/\" in entry['mxl']]\n",
    "        \n",
    "        # Enumerate unique genres from the \"primary_genre\" field.\n",
    "        unique_genres = set(entry['primary_genre'] for entry in self.entries)\n",
    "        print(\"PRIMARY GENRES:\", unique_genres)\n",
    "        self.genre_to_idx = {genre: idx for idx, genre in enumerate(sorted(unique_genres))}\n",
    "        \n",
    "        self.max_len = max_len\n",
    "        # Build vocabulary from the cached tokens if not provided.\n",
    "        if vocab is None:\n",
    "            self.vocab = self.build_vocab()\n",
    "        else:\n",
    "            self.vocab = vocab\n",
    "\n",
    "    def build_vocab(self):\n",
    "        counter = Counter()\n",
    "        # Build vocabulary using the precomputed tokens field.\n",
    "        for entry in self.entries:\n",
    "            # Parse the tokens from the JSON string stored in the \"tokens\" field.\n",
    "            tokens = json.loads(entry['tokens'])\n",
    "            counter.update(tokens)\n",
    "        # Start with special tokens.\n",
    "        vocab = {'<PAD>': 0, '<UNK>': 1, '<CLS>': 2}\n",
    "        for token, _ in counter.items():\n",
    "            if token not in vocab:\n",
    "                vocab[token] = len(vocab)\n",
    "\n",
    "        print(\"done building vocab\")\n",
    "        return vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.entries[idx]\n",
    "        # Load the cached tokens from the \"tokens\" field.\n",
    "        tokens = json.loads(entry['tokens'])\n",
    "        # Prepend a <CLS> token for classification.\n",
    "        tokens = ['<CLS>'] + tokens\n",
    "        # Convert tokens to token IDs using the vocabulary.\n",
    "        token_ids = [self.vocab.get(tok, self.vocab['<UNK>']) for tok in tokens]\n",
    "        # Truncate or pad the sequence to max_len.\n",
    "        if len(token_ids) > self.max_len:\n",
    "            token_ids = token_ids[:self.max_len]\n",
    "        else:\n",
    "            token_ids = token_ids + [self.vocab['<PAD>']] * (self.max_len - len(token_ids))\n",
    "        token_ids = torch.tensor(token_ids, dtype=torch.long)\n",
    "        \n",
    "        # Convert genre string to an integer label.\n",
    "        genre_str = entry['primary_genre']\n",
    "        genre = self.genre_to_idx[genre_str]\n",
    "        \n",
    "        return token_ids, genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Positional Encoding\n",
    "Useful for making sure the model understands the musical sequence and structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        if d_model % 2 == 1:\n",
    "            # if odd, handle last column\n",
    "            pe[:, 1::2] = torch.cos(position * div_term[:pe[:, 1::2].shape[1]])\n",
    "        else:\n",
    "            pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # Shape: (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, d_model)\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "Encoder-only as decoding is an expensive and largely irrelevant step in the process, when we can just get the \\<CLS\\> token from the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=512, nhead=8, num_layers=6, num_classes=10, max_len=512, dropout=0.1):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=2048, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Classifier head: you can use the <CLS> token embedding or a pooling over sequence outputs\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src shape: (batch_size, seq_len)\n",
    "        embedded = self.embedding(src)  # (batch_size, seq_len, d_model)\n",
    "        embedded = self.pos_encoder(embedded)\n",
    "        # PyTorch transformer expects shape: (seq_len, batch_size, d_model)\n",
    "        embedded = embedded.transpose(0, 1)\n",
    "        transformer_output = self.transformer_encoder(embedded)  # (seq_len, batch_size, d_model)\n",
    "        # Take the output corresponding to the <CLS> token (first token)\n",
    "        cls_output = transformer_output[0]  # (batch_size, d_model)\n",
    "        cls_output = self.dropout(cls_output)\n",
    "        logits = self.fc(cls_output)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for token_ids, labels in dataloader:\n",
    "        token_ids, labels = token_ids.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(token_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for token_ids, labels in dataloader:\n",
    "            token_ids, labels = token_ids.to(device), labels.to(device)\n",
    "            logits = model(token_ids)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(dataloader), accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "def test_model(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in dataloader:\n",
    "            outputs = model(features)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = 100 * correct / total if total > 0 else 0\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIMARY GENRES: {'R&B, Soul & Hip-Hop', 'Religious', 'Electronic & Dance', 'Rock & Metal', 'Pop', 'Jazz & Blues', 'Soundtrack', 'Classical', 'Folk/World'}\n",
      "done building vocab\n",
      "starting train\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Hyperparameters\n",
    "    json_path = 'preprocessed_dataset.json'\n",
    "    max_len = 512\n",
    "    batch_size = 32\n",
    "    num_classes = 9  # Adjust according to your dataset\n",
    "    d_model = 512\n",
    "    nhead = 8\n",
    "    num_layers = 6\n",
    "    num_epochs = 100\n",
    "    learning_rate = 1e-4\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Create dataset and split into training/validation sets\n",
    "    dataset = MusicXMLDataset(json_path, max_len=max_len)\n",
    "    vocab_size = len(dataset.vocab)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Instantiate model, optimizer, and loss function\n",
    "    model = TransformerClassifier(vocab_size, d_model=d_model, nhead=nhead, \n",
    "                                  num_layers=num_layers, num_classes=num_classes, \n",
    "                                  max_len=max_len).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()  # Start timer for the epoch\n",
    "    \n",
    "        print(\"starting train\")\n",
    "        train_loss = train_model(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
    "        \n",
    "        epoch_time = time.time() - start_time  # Compute elapsed time for the epoch\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f} ({epoch_time}s)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
